{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nengo\n",
    "import numpy as np\n",
    "\n",
    "from nengo_extras.data import load_mnist, one_hot_from_labels\n",
    "from nengo_extras.matplotlib import tile\n",
    "from nengo_extras.vision import Gabor, Mask\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = np.random.RandomState(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Playing with [image encoding](https://www.nengo.ai/nengo-extras/examples/mnist_single_layer.html) tutorial"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65.8%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data3/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data3/MNIST/raw/train-images-idx3-ubyte.gz to data3/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data3/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data3/MNIST/raw/train-labels-idx1-ubyte.gz to data3/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data3/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting data3/MNIST/raw/t10k-images-idx3-ubyte.gz to data3/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data3/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting data3/MNIST/raw/t10k-labels-idx1-ubyte.gz to data3/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import v2\n",
    "import torch\n",
    "\n",
    "# download MNIST data using torch instead of nengo_extras.data.load_mnist, whose url seems down\n",
    "dataset = MNIST(root = 'data3/', download = True, transform=v2.ToDtype(torch.float32) )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "# training data X is nparray of shape (60000 images, 28 pixels, 28 pixels)\n",
    "X = dataset.data.detach().numpy()\n",
    "\n",
    "# normalize pixel values from [0,255] to [-1,1]\n",
    "X = X / 255 * 2 - 1\n",
    "\n",
    "# labels Y of shape (60000 images, 10 categories)\n",
    "Y = one_hot_from_labels(dataset.targets.detach().numpy(), classes=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "X = X.reshape((60000,784))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 784)"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# --- set up network parameters\n",
    "n_vis = X.shape[1]\n",
    "n_out = Y.shape[1]\n",
    "print(n_vis)\n",
    "print(n_out)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with nengo.Network(seed=0) as model:\n",
    "    a = nengo.Ensemble(\n",
    "        n_neurons=1000,             # the more the better\n",
    "        dimensions=n_vis,                  # number of dimensions that can be input,\n",
    "        # also number of dimensions representable by output\n",
    "        eval_points=X,        # FIXME X_train is not 10D?\n",
    "        neuron_type=nengo.LIFRate(),   # Leaky-Integrate-and-Fire but nonspiking neurons\n",
    "        intercepts=nengo.dists.Choice([0.1]),  # choose turn-on = 0.1 for all neurons\n",
    "        max_rates=nengo.dists.Choice([100]),   # give all neurons same firing power\n",
    "    )\n",
    "\n",
    "    v = nengo.Node(size_in=n_out)\n",
    "\n",
    "    conn = nengo.Connection(\n",
    "        a, v, synapse=None, eval_points=X,\n",
    "        function=Y,                           # target function: return label when evaluated at each image\n",
    "        solver=nengo.solvers.LstsqL2(reg=0.01)      # optimize by solving L2-regularized least squares\n",
    "    )\n",
    "\n",
    "def get_outs(simulator, images):\n",
    "    # encode the images to get the ensemble activations\n",
    "    _, acts = nengo.utils.ensemble.tuning_curves(a, simulator, inputs=images)\n",
    "\n",
    "    # decode the ensemble activities using the connection's decoders\n",
    "    return np.dot(acts, simulator.data[conn].weights.T)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "application/vdom.v1+json": {
       "tagName": "div",
       "attributes": {}
      },
      "text/html": "\n                <script>\n                    if (Jupyter.version.split(\".\")[0] < 5) {\n                        var pb = document.getElementById(\"41b7f6ed-ae29-47a3-82e8-97ccc6bf5dd5\");\n                        var text = document.createTextNode(\n                            \"HTML progress bar requires Jupyter Notebook >= \" +\n                            \"5.0 or Jupyter Lab. Alternatively, you can use \" +\n                            \"TerminalProgressBar().\");\n                        pb.parentNode.insertBefore(text, pb);\n                    }\n                </script>\n                <div id=\"41b7f6ed-ae29-47a3-82e8-97ccc6bf5dd5\" style=\"\n                    width: 100%;\n                    border: 1px solid #cfcfcf;\n                    border-radius: 4px;\n                    text-align: center;\n                    position: relative;\">\n                  <div class=\"pb-text\" style=\"\n                      position: absolute;\n                      width: 100%;\">\n                    0%\n                  </div>\n                  <div class=\"pb-fill\" style=\"\n                      background-color: #bdd2e6;\n                      width: 0%;\">\n                    <style type=\"text/css\" scoped=\"scoped\">\n                        @keyframes pb-fill-anim {\n                            0% { background-position: 0 0; }\n                            100% { background-position: 100px 0; }\n                        }\n                    </style>\n                    &nbsp;\n                  </div>\n                </div>",
      "text/plain": "HtmlProgressBar cannot be displayed. Please use the TerminalProgressBar. It can be enabled with `nengo.rc['progress']['progress_bar'] = 'nengo.utils.progress.TerminalProgressBar'`."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vdom.v1+json": {
       "tagName": "div",
       "attributes": {
        "id": "0a0b3d83-fe12-4af2-b8c2-3a7b108e70e2",
        "style": {
         "width": "100%",
         "boxSizing": "border-box",
         "border": "1px solid #cfcfcf",
         "borderRadius": "4px",
         "textAlign": "center",
         "position": "relative"
        }
       },
       "children": [
        {
         "tagName": "div",
         "attributes": {
          "class": "pb-text",
          "style": {
           "position": "absolute",
           "width": "100%"
          }
         },
         "children": [
          "Building… 50%, ETA: 0:00:01"
         ]
        },
        {
         "tagName": "div",
         "attributes": {
          "class": "pb-fill",
          "style": {
           "width": "50%",
           "animation": "none",
           "backgroundColor": "#bdd2e6",
           "backgroundImage": "none",
           "transition": "width 0.1s linear"
          }
         },
         "children": [
          {
           "tagName": "style",
           "attributes": {
            "type": "text/css",
            "scoped": "scoped"
           },
           "children": [
            "\n                        @keyframes pb-fill-anim {\n                            0% { background-position: 0 0; }\n                            100% { background-position: 100px 0; }\n                        }}"
           ]
          },
          " "
         ]
        }
       ]
      },
      "text/html": "<script>\n              (function () {\n                  var root = document.getElementById('41b7f6ed-ae29-47a3-82e8-97ccc6bf5dd5');\n                  var text = root.getElementsByClassName('pb-text')[0];\n                  var fill = root.getElementsByClassName('pb-fill')[0];\n\n                  text.innerHTML = 'Building&hellip; 50%, ETA: 0:00:01';\n                  \n            if (50.0 > 0.) {\n                fill.style.transition = 'width 0.1s linear';\n            } else {\n                fill.style.transition = 'none';\n            }\n\n            fill.style.width = '50.0%';\n            fill.style.animation = 'none';\n            fill.style.backgroundImage = 'none'\n        \n                  \n              })();\n        </script>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    get_outs(sim, X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 10)"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_outs(sim,X).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "ScatteredHypersphere(surface=True)"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.encoders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
